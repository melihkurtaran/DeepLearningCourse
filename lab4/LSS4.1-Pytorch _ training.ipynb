{"cells":[{"cell_type":"markdown","source":["<img src=\"https://drive.google.com/uc?export=view&id=1x-QAgitB-S5rxGGDqxsJ299ZQTfYtOhb\" width=180, align=\"center\"/>\n","\n","Master's degree in Intelligent Systems\n","\n","Subject: 11754 - Deep Learning\n","\n","Year: 2022-2023\n","\n","Professor: Miguel √Ångel Calafat Torrens"],"metadata":{"id":"PUu2VSg0UO91"},"id":"PUu2VSg0UO91"},{"cell_type":"markdown","id":"auburn-therapy","metadata":{"id":"auburn-therapy"},"source":["# Lab 4.1 - Pytorch and training\n","In the previous lab, we trained a neural network, so you've already covered most of the important python concepts for working with neural networks. However, in this practice, we will delve into those that, although they do not form the conceptual base, are absolutely necessary to be able to carry out the work effectively and efficiently."]},{"cell_type":"markdown","metadata":{"id":"QHdYAzcHm_y-"},"source":["## Dataset and dataloader objects\n","[Datasets & Dataloaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)\n","\n","Pytorch provides these two classes, which you can import from: torch.utils.data.DataLoader and torch.utils.data.Dataset . These classes allow you to use preloaded data sets as well as your own data. _Dataset_ stores the location of the samples with their labels, while _DataLoader_ is an iterable that gives ordered access to the different data in _dataset_.\n","\n","Next, the _dataset_ [MNIST](https://pytorch.org/vision/stable/datasets.html#qmnist) is used, which is one of those that are already preloaded by default in pytorch. You can find the [information](https://github.com/facebookresearch/qmnist/blob/main/README.md) and [license](https://github.com/facebookresearch/qmnist/blob/main/LICENSE) in the corresponding hyperlinks."],"id":"QHdYAzcHm_y-"},{"cell_type":"code","source":["# Connect to your drive\n","from google.colab import drive, files\n","drive.mount('/content/gdrive')\n","%cd '/content/gdrive/MyDrive/Colab Notebooks/2022-2023-Lab.DL'\n","%ls -l\n","\n","# Here the path of the project folder (which is where this file is) is inserted\n","# into the python path.\n","import pathlib\n","import sys\n","\n","PROJECT_DIR = str(pathlib.Path().resolve())\n","sys.path.append(PROJECT_DIR)"],"metadata":{"id":"gP0_MIRNnQqY"},"id":"gP0_MIRNnQqY","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dVvjprEQm_zA"},"outputs":[],"source":["from torchvision import datasets\n","import torchvision.transforms as transforms\n","from torch.utils.data.sampler import SubsetRandomSampler\n","from torch.utils.data import random_split\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import time\n","import copy\n","import helper_PR4 as hp\n","import importlib\n","\n","SEED = 4\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)"],"id":"dVvjprEQm_zA"},{"cell_type":"code","source":["# Notice that the dataset used is from torchvision; that is, it is\n","# an image database. In this case, the images show handwritten digits\n","\n","# Before importing the data it is required to define the type of transformation\n","# to be applied. This will be seen in detail later. now just apply\n","# a transform that converts the data into pytorch tensors\n","transform = transforms.ToTensor()\n","\n","# A training dataset and a test dataset are assigned. The only difference\n","# when downloading it is that we put train=False in the test\n","train_data = datasets.MNIST(root='data',\n","                            train=True,\n","                            download=True,\n","                            transform=transform)\n","test_dataset = datasets.MNIST(root='data',\n","                              train=False,\n","                              download=True,\n","                              transform=transform)"],"metadata":{"id":"5X4zaWYu1xnk"},"id":"5X4zaWYu1xnk","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0cYT_m_ym_zC"},"outputs":[],"source":["# Let's have a look to these objects and their attributes\n","print(type(train_data))\n","print(hp.inspect_obj(train_data)['attributes'])"],"id":"0cYT_m_ym_zC"},{"cell_type":"code","execution_count":null,"metadata":{"id":"LhuhIGifm_zD"},"outputs":[],"source":["# The first attribute found is 'class_to_idx'. It is a dictionary that maps the\n","# names of the classes or categories of images with an identifying index. In\n","# this case we have 10 different classes (the ten digits) each with its index.\n","print(type(train_data.class_to_idx))\n","print(train_data.class_to_idx)"],"id":"LhuhIGifm_zD"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5fiU9z5Cm_zE"},"outputs":[],"source":["# There is also the 'classes' attribute, which directly lists the class names\n","# in the same order as they appear in 'class_to_idx'\n","print(type(train_data.classes))\n","print(train_data.classes)"],"id":"5fiU9z5Cm_zE"},{"cell_type":"code","execution_count":null,"metadata":{"id":"KtFgwN9um_zE"},"outputs":[],"source":["# Another interesting attribute is 'data'. Upon inspection you will see that it\n","# is a 60,000 position tensor, each of which is a 28x28 matrix. Here we've got\n","# the data to be used\n","ob = train_data.data\n","print(type(ob))\n","print(ob.shape)"],"id":"KtFgwN9um_zE"},{"cell_type":"markdown","source":["If you wanted to customize your dataset object, you should override the `__len__` and `__getitem__` methods. We aren't doing it in this example because we already have the behavior wanted.\n","\n","https://pytorch.org/tutorials/beginner/data_loading_tutorial.html#dataset-class"],"metadata":{"id":"qvkVlNtm73rW"},"id":"qvkVlNtm73rW"},{"cell_type":"code","source":["# Let's see some methods of this class. Check that __len__ and __getitem__ exist\n","print(hp.inspect_obj(train_data, internal=True)['methods'])"],"metadata":{"id":"TKdASBLR5EOv"},"id":"TKdASBLR5EOv","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Furthermore, as you've seen in theory, we're going to use a percentage of the\n","# training images for validation. This is necessary to control overfitting.\n","val_size = 0.2\n","num_train = len(train_data)\n","\n","# Number of items of the validation dataset\n","num_val = int(val_size * num_train)\n","\n","# Adjust the size of the training set accordingly\n","num_train = num_train - num_val\n","\n","# Split the training dataset into train and validation sets\n","train_dataset, valid_dataset = random_split(train_data, [num_train, num_val])\n","\n","# Print the number of samples in each set\n","print(f\"Number of samples in train set: {len(train_dataset)}\")\n","print(f\"Number of samples in validation set: {len(valid_dataset)}\")\n"],"metadata":{"id":"LtY2TYvNARVO"},"id":"LtY2TYvNARVO","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oSZdATJ_m_zG"},"outputs":[],"source":["# Let's go there with the dataloaders. First of all, as we have done with the\n","# datasets, let's define the necessary parameters\n","\n","# num_workers is the number of threads that you can have in parallel\n","# If you're doing this in Colab, the maximum is 2. If you're doing it locally\n","# with your own GPU, you'll be able to increase it.\n","num_workers = 2  # 6\n","\n","# Next comes the batch size. This indicates how many samples there will be for\n","# each batch. It shouldn't be too small because it doesn't use all available\n","# resources, nor too big because it clutters memory.\n","# In this case, very large sizes could be used since the images take up little\n","# space; but we will use a smaller number for practicality\n","batch_size = 1024  # 1024"],"id":"oSZdATJ_m_zG"},{"cell_type":"code","execution_count":null,"metadata":{"id":"dvIEWe3km_zI"},"outputs":[],"source":["# And finally we define the dataloaders\n","train_loader = torch.utils.data.DataLoader(train_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=True,\n","                                           num_workers=num_workers)\n","valid_loader = torch.utils.data.DataLoader(valid_dataset,\n","                                           batch_size=batch_size,\n","                                           shuffle=False,\n","                                           num_workers=num_workers)\n","test_loader = torch.utils.data.DataLoader(test_dataset,\n","                                          batch_size=batch_size,\n","                                          shuffle=False,\n","                                          num_workers=num_workers)"],"id":"dvIEWe3km_zI"},{"cell_type":"markdown","metadata":{"id":"CjgTw4U7m_zJ"},"source":["Dataloader provides an iterable over the _dataset_. Specifically, it is a generator. In the last lab you iterated directly over the dataset using its indices. The usual thing is to iterate over the _dataloader_. Let's see what's in the first batch."],"id":"CjgTw4U7m_zJ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2NeFa4NSm_zJ"},"outputs":[],"source":["# As before, let's inspect these objects. You will see that the dataloader\n","# contains the dataset\n","ob = train_loader\n","print(hp.inspect_obj(ob)['attributes'])\n","print(type(ob))\n","print(ob)"],"id":"2NeFa4NSm_zJ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"sUVcTi1cm_zK"},"outputs":[],"source":["# Let's see what's in the first batch.\n","data_iter = iter(train_loader)\n","images, labels = next(data_iter)\n","\n","# The images are provided as a tensor of as many positions as the batch defined,\n","# and then, each image is a tensor of 1 x 28 x 28 pixels\n","print(images.shape)\n","print(labels.shape)"],"id":"sUVcTi1cm_zK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5zROYJg8m_zK"},"outputs":[],"source":["# Check the first image and its associated label\n","n = 0\n","plt.imshow(images[n].numpy().squeeze(), cmap='gray')\n","print('Label: {}'.format(labels.numpy()[n].item()))"],"id":"5zROYJg8m_zK"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ypwQXVJqm_zL"},"outputs":[],"source":["# Now that we know what we have, let's go through the whole batch.\n","fig = plt.figure(figsize=(25, 8))\n","bs = 32 if batch_size > 32 else batch_size\n","for k in range(bs):\n","    nrs = int(np.ceil(bs / 8))\n","    ax = fig.add_subplot(nrs, 8, k + 1, xticks=[], yticks=[])\n","    ax.imshow(images[k].numpy().squeeze(), cmap='gray')\n","    # The correct label is included on each image\n","    ax.set_title(str(labels[k].item()))"],"id":"ypwQXVJqm_zL"},{"cell_type":"markdown","metadata":{"id":"qwTvhwDXm_zM"},"source":["## The neural network\n","\n","Next, a neural network is defined as it was done in the previous practice. Note that ReLU is used as the activation layer between dense layers. This prevents the gradient from fading. In addition, dropout layers are also incorporated. Initially they are disabled (p=0.0); but later you will be asked to modify this value."],"id":"qwTvhwDXm_zM"},{"cell_type":"code","execution_count":null,"metadata":{"id":"FX97Vnham_zN"},"outputs":[],"source":["class Network(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        # Dense layers\n","        # Three dense layers are defined. The input of the first hidden layer\n","        # will have as many units as pixels in the image. The output of the\n","        # last layer will have as many units as classes we want to identify, in\n","        # this case 10 digits\n","        self.fc1 = nn.Linear(in_features=28 * 28, out_features=256, bias=True)\n","        self.fc2 = nn.Linear(in_features=256, out_features=64, bias=True)\n","        self.fc3 = nn.Linear(in_features=64, out_features=10, bias=True)\n","        \n","        # Activation layers\n","        self.relu = nn.ReLU()\n","        \n","        # Dropout layers.\n","        # The parameter p is the probability of each unit to be turned off in\n","        # the current epoch. We'll see an example shortly. The dropout is now\n","        # set to disabled.\n","        self.dropout = nn.Dropout(p=0.0)\n","    \n","    # Definition of forward pass method\n","    def forward(self, x):\n","        # The inputs will propagate forward through all the defined layers. The\n","        # behavior is specified by each function.\n","        x = x.view(-1, 28 * 28)  # in: b x 28 x 28  out: b x 784\n","        x = self.relu(self.fc1(x))  # in: b x 784  out: b x 256\n","        x = self.dropout(x)\n","        x = self.relu(self.fc2(x))  # in: b x 256  out: b x 64\n","        x = self.dropout(x)\n","        x = self.relu(self.fc3(x))  # in: b x 64  out: b x 10\n","        # Notice how in this case there is no output activation that converts\n","        # the scores into probabilities.\n","        \n","        return x"],"id":"FX97Vnham_zN"},{"cell_type":"code","execution_count":null,"metadata":{"id":"yJxs_Ohvm_zN"},"outputs":[],"source":["# DEVICE is defined. It is capitalized to identify that it is a global variable.\n","# This is a convention, not a rule. You can put it however you want, although\n","# you should keep in mind that python is case sensitive.\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(DEVICE)"],"id":"yJxs_Ohvm_zN"},{"cell_type":"code","execution_count":null,"metadata":{"id":"KKEdM9Kwm_zM"},"outputs":[],"source":["# Reset seed for reproducibility\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)"],"id":"KKEdM9Kwm_zM"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZQZmHPVcm_zN"},"outputs":[],"source":["# The model is instantiated\n","model = Network()\n","print(model)\n","\n","model = model.to(DEVICE)"],"id":"ZQZmHPVcm_zN"},{"cell_type":"markdown","metadata":{"id":"eipR6MtSm_zO"},"source":["## Loss function\n","\n","For classification, as in this case, it is convenient to use a loss function of the Cross-Entropy type. In the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss) you will find the specifications. You will see that the input of this function is the output of the network **without being converted to probabilities** (this is usually referred to in the documentation as _scores_ or _logits_). This is the reason why an activation layer has not been included in the network output. Therefore, one must be aware that when the output probability is required, the corresponding function will have to be applied, which in this case is Softmax."],"id":"eipR6MtSm_zO"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ujEf1BJ3m_zO"},"outputs":[],"source":["# Loss function Cross-Entropy\n","criterion = nn.CrossEntropyLoss()"],"id":"ujEf1BJ3m_zO"},{"cell_type":"code","execution_count":null,"metadata":{"id":"O0Cxhr3Jm_zO"},"outputs":[],"source":["# The optimizer is defined. In this case we tried Adam. It is usually a good\n","# option in terms of convergence speed\n","# https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.02)"],"id":"O0Cxhr3Jm_zO"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1XQU8Pmbm_zO"},"outputs":[],"source":["# We arrange the dataloaders in a single object\n","loaders = {'train': train_loader, 'valid': valid_loader, 'test': test_loader}"],"id":"1XQU8Pmbm_zO"},{"cell_type":"markdown","metadata":{"id":"AVvM0T1Tm_zP"},"source":["## The training\n","\n","In the last practice we already saw how to train the model. In that case, considerations were not yet made to avoid overfitting. In this case, the training will incorporate validation, which will serve precisely for this. The comparison between training and validation losses is valuable information to know wether the model is overfitting."],"id":"AVvM0T1Tm_zP"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0F8fSwb8m_zP"},"outputs":[],"source":["def train_pass(data, target, model, optimizer, criterion):\n","    data, target = data.to(DEVICE), target.to(DEVICE)\n","    optimizer.zero_grad()\n","    output = model(data)\n","    loss = criterion(output, target)\n","    loss.backward()\n","    optimizer.step()\n","    return loss.item()\n","\n","def valid_pass(data, target, model, criterion):\n","    data, target = data.to(DEVICE), target.to(DEVICE)\n","    with torch.no_grad():\n","        output = model(data)\n","    loss = criterion(output, target)\n","    return loss.item()"],"id":"0F8fSwb8m_zP"},{"cell_type":"code","execution_count":null,"metadata":{"id":"-u4ewjhSm_zR"},"outputs":[],"source":["# Training function. Conceptually it is the same as in the previous practice,\n","# but now it incorporates validation.\n","def train(n_epochs, loaders, model, optimizer, criterion):\n","    \n","    valid_loss_min = np.Inf \n","    tr_loss_list = []  # Training loss values list (per epoch)\n","    vl_loss_list = []  # Validation loss values list (per epoch)\n","    \n","    # Loop through epochs\n","    for epoch in range(1, n_epochs + 1):\n","        start_time = time.time()\n","        model.train()\n","        train_loss, valid_loss = 0.0, 0.0\n","        \n","        # Training\n","        for data, target in loaders['train']:\n","            train_loss += train_pass(data, target, model, optimizer, criterion)\n","        # Training losses log\n","        tr_loss_list.append(train_loss / len(loaders['train']))\n","        \n","        # Validation\n","        model.eval()\n","        for data, target in loaders['valid']:\n","            valid_loss += valid_pass(data, target, model, criterion)\n","        # Validation losses log\n","        vl_loss_list.append(valid_loss / len(loaders['valid']))\n","\n","        # Results\n","        end_time = time.time()\n","        print('Epoch: {} \\tTraining loss: {:.5f} \\tValidation loss: {:.5f}\\\n","            \\t Time: {:.1f} s'.format(epoch, tr_loss_list[-1],\n","                                      vl_loss_list[-1], end_time - start_time))\n","    return model, (tr_loss_list, vl_loss_list)"],"id":"-u4ewjhSm_zR"},{"cell_type":"code","execution_count":null,"metadata":{"id":"VuV6Q1yRm_zR"},"outputs":[],"source":["# Run this training to see how it works\n","n_epochs = 40\n","model, tr_data = train(n_epochs, loaders, model, optimizer, criterion)"],"id":"VuV6Q1yRm_zR"},{"cell_type":"markdown","metadata":{"id":"qTnj95jom_zR"},"source":["Observe how in the previous training the validation best fit does not occur in the last epoch. Next, a plot will be generated to be able to appreciate more clearly what has happened in this training."],"id":"qTnj95jom_zR"},{"cell_type":"code","execution_count":null,"metadata":{"id":"kFDDwhKnm_zR"},"outputs":[],"source":["# Generate the plot\n","x = range(1, 1 + len(tr_data[0]))\n","tr_losses, vl_losses = tr_data[0], tr_data[1]\n","tr_max, tr_min = np.max(tr_losses), np.min(tr_losses)\n","epoch_min = 1 + np.argmin(vl_losses)\n","val_min = np.min(vl_losses)\n","\n","plt.plot(x, tr_data[0], label='training loss')\n","plt.plot(x, tr_data[1], label='validation loss')\n","plt.xlabel('epochs')\n","plt.ylabel('loss')\n","plt.title(\"Losses during training\")\n","plt.legend()\n","plt.annotate('valid min: {:.4f}'.format(val_min), xy=(epoch_min, val_min),\n","             xytext=(round(0.75 * len(tr_losses)), 3*(tr_max - tr_min)/4 + tr_min),\n","             arrowprops=dict(facecolor='black', shrink=0.05),\n","             )\n","plt.xlim(0, len(tr_losses))\n","plt.show()"],"id":"kFDDwhKnm_zR"},{"cell_type":"markdown","metadata":{"id":"7cJPFEggm_zS"},"source":["The first conclusion drawn from this training is that, as things have been done, the final trained model is not the best model (the one with the parameters that generalize better in validation). This implies that the best adjustment must be recorded as it occurs.\n","\n","On the other hand, it can be seen how the validation losses follow a growing trend, while the training losses follow a decreasing trend, the latter being clearly lower. This is a clear overfitting situation.\n","\n","One of the best techniques to prevent overfitting is the use of dropout layers. In the previous case, dropout layers have been defined; but they have been deactivated when selecting p=0. They will then be activated with p=0.4. This implies that each unit has a 40% chance of turning off in each epoch; that is, on average there will be 40% of the units disabled in each epoch. This way it is avoided that the adjustment falls on only a few units."],"id":"7cJPFEggm_zS"},{"cell_type":"code","execution_count":null,"metadata":{"id":"Iwalg3Tlm_zS"},"outputs":[],"source":["# The random seed is reset to redo the training starting from the same point.\n","del model, optimizer\n","torch.cuda.empty_cache()\n","\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","\n","# The model is instantiated\n","model = Network()\n","# This time with dropout p=0.4\n","model.dropout = nn.Dropout(p=0.4)\n","model = model.to(DEVICE)\n","# The new model optimizer is instantiated\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.02)\n","# Do the training\n","model, tr_data = train(n_epochs, loaders, model, optimizer, criterion)"],"id":"Iwalg3Tlm_zS"},{"cell_type":"code","execution_count":null,"metadata":{"id":"FaWkmzpem_zS"},"outputs":[],"source":["# The plot is generated\n","x = range(1, 1 + len(tr_data[0]))\n","tr_losses, vl_losses = tr_data[0], tr_data[1]\n","tr_max, tr_min = np.max(tr_losses), np.min(tr_losses)\n","epoch_min = 1 + np.argmin(vl_losses)\n","val_min = np.min(vl_losses)\n","\n","plt.plot(x, tr_data[0], label='training loss')\n","plt.plot(x, tr_data[1], label='validation loss')\n","plt.xlabel('epochs')\n","plt.ylabel('loss')\n","plt.title(\"Losses during training\")\n","plt.legend()\n","plt.annotate('valid min: {:.4f}'.format(val_min), xy=(epoch_min, val_min),\n","             xytext=(round(0.75 * len(tr_losses)), 3*(tr_max - tr_min)/4 + tr_min),\n","             arrowprops=dict(facecolor='black', shrink=0.05),\n","             )\n","plt.xlim(0, len(tr_losses))\n","plt.show()"],"id":"FaWkmzpem_zS"},{"cell_type":"markdown","metadata":{"id":"Fk7kpeiym_zT"},"source":["Notice how applying this dropout value, with the same initial weights, the value of the validation adjustment is noticeably better than before. Furthermore, at this point we cannot say that we have overfitting, since the validation losses are better (lower) than the training losses.\n","\n","Why are validation losses lower than training losses in this case?\n","\n","**Answer:**\n","We are applying a dropout during training to avoid overfitting. This technique, as we have seen, is only applied during training and not during validation. If the dropout parameter is too aggressive, then it doesn't allow the model to fit properly during training; for this reason validation, which does not have the handicap of the dropout, offers better results."],"id":"Fk7kpeiym_zT"},{"cell_type":"markdown","source":["As a general rule, it is considered that the model generalizes better in a range between the crossing point of the two curves and the minimum of the validation curve.\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1nZbwtJ5thQXdWlkc1xlRX1u3iDbrrZk2\" width=400, align=\"center\"/>\n"],"metadata":{"id":"EzfM6LvrVqtL"},"id":"EzfM6LvrVqtL"},{"cell_type":"markdown","metadata":{"id":"LUNmwK1Am_zT"},"source":["Although unfortunately the training curves do not always have an ideal situation. Sometimes the curves don't intersect; other times the validation curve ends with a horizontal trend, or with a slight positive or negative slope; other times there is a sudden step down because the model was stuck in a local minimum; other times there is a lot of noise and it is not clear, etc. In each case, the appropriate considerations must be made, taking into account the gap between the two curves and the slopes.\n","\n","Below is a comparison of several training sessions with or without different dropout levels and with different random seeds (the SEED variable that is defined at the beginning of this _notebook_). Do not lose sight of the fact that each random seed implies different initial weights, so logically you can find a combination that improves the ones shown or that have anomalous behaviors. However, use this graph to verify the importance of the initial weights, the validation control and the number of epochs to train.\n","The validation minimum is indicated by an arrow.\n","\n","<img src=\"https://drive.google.com/uc?export=view&id=1ZFFrpC6MG1zlnMy4p9T8hm2yMctFWnlF\" width=2000>"],"id":"LUNmwK1Am_zT"},{"cell_type":"markdown","metadata":{"id":"4GjycssTm_zU"},"source":["Whatever, it is clear that we cannot always select the model of the last trained epoch, since it does not have to be the best model. Therefore, it is convenient to save the best model as it appears."],"id":"4GjycssTm_zU"},{"cell_type":"markdown","metadata":{"id":"rARIPIU4m_zU"},"source":["## Saving and loading models\n","\n","In general saving and loading models in pytorch is quite simple. In principle, the immediate saving would be the trained weights. This would be done directly with the following instructions:\n","\n","* torch.save(model.state_dict(), PATH) -> Save the state dictionary\n","* model.load_state_dict(torch.load(PATH)) -> Load the state dictionary into the model\n","\n","This type of saving and loading is the most suitable for making inferences. The entire model can also be saved; but this is less common and takes up much more space.\n","\n","If what is intended is not only to make inferences, but also to retrain, then the usual thing is to save other training parameters that are useful to resume it. [For example](https://pytorch.org/tutorials/beginner/saving_loading_models.html#saving-loading-a-general-checkpoint-for-inference-and-or-resuming-training), as described in the official pytorch tutorials:\n","```\n","torch.save({\n","            'epoch': epoch,\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'vl_loss': vl_loss,\n","            ...\n","            }, PATH)\n","```\n","\n","When loading the model, before making the value assignments, the type of model and optimizer would have to be loaded. Then you would have to assign to each variable the corresponding value of the field stored in the dictionary:\n","\n","```\n","checkpoint = torch.load(PATH)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","last_epoch_trained = checkpoint['epoch']\n","vl_loss = checkpoint['vl_loss']\n","...\n","```\n","\n","Finally, depending on what is going to be done next, the model will be put into evaluation or training mode."],"id":"rARIPIU4m_zU"},{"cell_type":"code","execution_count":null,"metadata":{"id":"UYEykYwzm_zV"},"outputs":[],"source":["# Let's look at one possibility for the model saving and loading functions.\n","# Keep in mind that you can save any other parameter that you consider of\n","# interest.\n","def trained_save(filename, model, optimizer, tr_loss_list, vl_loss_list):\n","    custom_dict = {'model_state_dict': model.state_dict(),\n","                   'opt_state_dict': optimizer.state_dict(),\n","                   'tr_loss_list': tr_loss_list,\n","                   'vl_loss_list': vl_loss_list}\n","    torch.save(custom_dict, filename)\n","    print('Checkpoint saved at epoch {}'.format(len(tr_loss_list)))\n","    \n","\n","def trained_load(filename, model, optimizer):\n","    checkpoint = torch.load(filename)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","    optimizer.load_state_dict(checkpoint['opt_state_dict'])\n","    checkpoint.pop('model_state_dict')\n","    checkpoint.pop('opt_state_dict')\n","\n","    return model, optimizer, checkpoint"],"id":"UYEykYwzm_zV"},{"cell_type":"code","execution_count":null,"metadata":{"id":"aqxgi1Unm_zW"},"outputs":[],"source":["# And now the training function is modified accordingly. Notice that at first\n","# it checks if a checkpoint is passed. Note that recording results saves the\n","# checkpoint to disk. The function outputs the best trained model.\n","\n","def train(n_epochs, loaders, model, optimizer, criterion, checkpoint={}):\n","    \n","    # Training data recovery if applicable\n","    if bool(checkpoint):\n","        tr_loss_list = checkpoint['tr_loss_list']\n","        vl_loss_list = checkpoint['vl_loss_list']\n","        valid_loss_min = np.min(vl_loss_list)\n","        trained_epochs = len(tr_loss_list)\n","        best_state_dict = copy.deepcopy(model.state_dict())\n","    else:\n","        tr_loss_list = []\n","        vl_loss_list = []\n","        valid_loss_min = np.Inf\n","        trained_epochs = 0\n","        best_state_dict = {}\n","\n","    # Loop through epochs\n","    for epoch in range(1 + trained_epochs, n_epochs + trained_epochs + 1):\n","        start_time = time.time()\n","        model.train()\n","        train_loss, valid_loss = 0.0, 0.0\n","        \n","        # Training\n","        # Loop through batches\n","        for data, target in loaders['train']:\n","            train_loss += train_pass(data, target, model, optimizer, criterion)\n","        # Training losses log per epoch\n","        tr_loss_list.append(train_loss / len(loaders['train']))\n","        \n","        # Validation\n","        model.eval()\n","        for data, target in loaders['valid']:\n","            valid_loss += valid_pass(data, target, model, criterion)\n","         # Validation losses log per epoch\n","        vl_loss_list.append(valid_loss / len(loaders['valid']))\n","\n","        # Results\n","        end_time = time.time()\n","        print('Epoch: {} \\tTraining loss: {:.5f} \\tValidation loss: {:.5f}\\\n","            \\t Time: {:.1f} s'.format(epoch, tr_loss_list[-1],\n","                                      vl_loss_list[-1], end_time - start_time))\n","        \n","        # Recording of results if best validation fit is given\n","        if vl_loss_list[-1] < valid_loss_min:\n","            best_state_dict = copy.deepcopy(model.state_dict())\n","            trained_save(FILENAME, model, optimizer, tr_loss_list, vl_loss_list)\n","            valid_loss_min = vl_loss_list[-1]\n","    \n","    # The best model is returned and the training data are written before\n","    # exiting\n","    model.load_state_dict(best_state_dict)\n","    trained_save(FILENAME, model, optimizer, tr_loss_list, vl_loss_list)\n","\n","    return model, (tr_loss_list, vl_loss_list)"],"id":"aqxgi1Unm_zW"},{"cell_type":"code","execution_count":null,"metadata":{"id":"tFvLOskrm_zY"},"outputs":[],"source":["# # The name of the file is defined as a global variable, since it will not be\n","# passed as an argument to the 'train' function, but it will be used.\n","FILENAME = 'pr4model.pt'"],"id":"tFvLOskrm_zY"},{"cell_type":"code","execution_count":null,"metadata":{"id":"N1W77LMPm_zZ"},"outputs":[],"source":["# The random seed is reset to redo the training starting from the same point.\n","del model, optimizer\n","torch.cuda.empty_cache()\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","\n","# The model is instantiated\n","model = Network()\n","# This time with dropout p=0.3\n","model.dropout = nn.Dropout(p=0.3)\n","model = model.to(DEVICE)\n","# The new model optimizer is instantiated\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.02)"],"id":"N1W77LMPm_zZ"},{"cell_type":"code","execution_count":null,"metadata":{"id":"nwHkcEQ1m_za"},"outputs":[],"source":["# Let's do the training again. This time saving the best model.\n","n_epochs = 26\n","model, tr_data = train(n_epochs, loaders, model, optimizer, criterion)"],"id":"nwHkcEQ1m_za"},{"cell_type":"code","execution_count":null,"metadata":{"id":"P7GycuUPm_zb"},"outputs":[],"source":["# Now a checkpoint with the best result and the simulation data will have been\n","# automatically saved.\n","model, optimizer, checkpoint = trained_load(FILENAME, model, optimizer)"],"id":"P7GycuUPm_zb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNUhofePm_zc"},"outputs":[],"source":["# We define a function to plot the training\n","def plot_checkpoint(checkpoint):\n","    x = range(1, 1 + len(checkpoint['tr_loss_list']))\n","    tr_losses, vl_losses = checkpoint['tr_loss_list'], checkpoint['vl_loss_list']\n","    tr_max, tr_min = np.max(tr_losses), np.min(tr_losses)\n","    epoch_min = 1 + np.argmin(vl_losses)\n","    val_min = np.min(vl_losses)\n","\n","    plt.plot(x, tr_losses, label='training loss')\n","    plt.plot(x, vl_losses, label='validation loss')\n","    plt.xlabel('epochs')\n","    plt.ylabel('loss')\n","    plt.title(\"Losses during training\")\n","    plt.legend()\n","    plt.annotate('valid min: {:.4f}'.format(val_min), xy=(epoch_min, val_min),\n","                 xytext=(round(0.75 * len(tr_losses)), 3*(tr_max - tr_min)/4 + tr_min),\n","                 arrowprops=dict(facecolor='black', shrink=0.05),\n","                 )\n","    plt.xlim(0, len(tr_losses))\n","    plt.show()"],"id":"pNUhofePm_zc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"_59XXzUnm_zc"},"outputs":[],"source":["# Plot it\n","plot_checkpoint(checkpoint)"],"id":"_59XXzUnm_zc"},{"cell_type":"code","execution_count":null,"metadata":{"id":"XUOA_9Gim_zd"},"outputs":[],"source":["# Now let's see what happens if you train a few more epochs. Notice that the\n","# checkpoint is passed as an argument. Also, at this point we can modify the\n","# learning rate if we consider that this can improve the training.\n","for d in optimizer.param_groups: d['lr'] = 0.01\n","\n","# Let's train again\n","n_epochs = 14\n","model, tr_data = train(n_epochs, loaders, model, optimizer, criterion, checkpoint)"],"id":"XUOA_9Gim_zd"},{"cell_type":"code","execution_count":null,"metadata":{"id":"8a7Iez9nm_ze"},"outputs":[],"source":["# The results are displayed. Notice how the complete training is displayed,\n","# combining both the previous and the current one.\n","plot_checkpoint(checkpoint)"],"id":"8a7Iez9nm_ze"},{"cell_type":"markdown","metadata":{"id":"iBB56y6Km_zf"},"source":["## Test the model\n","\n","Once the model has been trained and validated, next we have to test it with data that it has never seen before. For this we are going to use the _test_loader_ defined at the beginning of this lab.\n","\n","**Before continuing, do the problem 1 of the notebook `Lab-4.ipynb` and then come back here**"],"id":"iBB56y6Km_zf"},{"cell_type":"code","source":["# In case you want to reload the helper function, execute this cell\n","importlib.reload(hp)"],"metadata":{"id":"h-_5Xy4SYS8K"},"id":"h-_5Xy4SYS8K","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# See the content of the helper file\n","files.view(hp.__name__ + '.py')"],"metadata":{"id":"nIqIgoezw9x_"},"id":"nIqIgoezw9x_","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# If your functions are correct you should see the message\n","# \"All tests passed!\" when executing this command uncommented\n","# !python 'helper_PR4.py'"],"metadata":{"id":"XnWPKrzg_sFM"},"id":"XnWPKrzg_sFM","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AVSIf5Kdm_zi"},"outputs":[],"source":["# Very high accuracy values can be achieved, although one reason for this is\n","# that the type of images is very constrained\n","accuracy, test_loss, outputs = hp.do_test(model, loaders, criterion)\n","\n","# If you haven't changed the seed, you should see an accuracy of 0.86\n","print('Accuracy: {:.2f}'.format(accuracy))"],"id":"AVSIf5Kdm_zi"},{"cell_type":"markdown","metadata":{"id":"FRkPc1Ihm_zj"},"source":["### Probability\n","\n","When calculating the precision, there was no need to calculate the odds that the system gives each class of being correct. This data may be of interest in some applications, since probabilities that are not high enough could cause the system's prediction to be discarded and vice versa.\n","\n","Let's see how to calculate it. Remember that in the defined model the output did not have an activation layer that converted the values into probabilities. An output of this type is often called _scores_ or _logits_. To have the probabilities, you only have to apply the corresponding activation layer. For the case at hand, a classification, we will use Softmax."],"id":"FRkPc1Ihm_zj"},{"cell_type":"code","execution_count":null,"metadata":{"id":"RF_Wtdu5m_zj"},"outputs":[],"source":["# We select the first iteration of the test dataloader\n","data_iter = iter(test_loader)\n","images, labels = next(data_iter)"],"id":"RF_Wtdu5m_zj"},{"cell_type":"code","execution_count":null,"metadata":{"id":"d0PJKI1Hm_zj"},"outputs":[],"source":["# We apply a test step and obtain logits\n","_, output = hp.test_pass(images, labels, model, criterion)\n","print(output.shape)"],"id":"d0PJKI1Hm_zj"},{"cell_type":"code","execution_count":null,"metadata":{"id":"sf6X-_Jhm_zj"},"outputs":[],"source":["# We apply the activation layer and get probabilities\n","output_prob = torch.softmax(output, dim=1)"],"id":"sf6X-_Jhm_zj"},{"cell_type":"code","execution_count":null,"metadata":{"id":"l7g4DBZom_zk"},"outputs":[],"source":["# To check that there was no error, let's look at the result of the first\n","# image. It is a vector of probabilities.\n","print(output_prob[0])"],"id":"l7g4DBZom_zk"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5_RGdqCam_zk"},"outputs":[],"source":["# The sum of the 10 probabilities associated with this image should be equal\n","# to 1, since there are only these 10 possible outputs.\n","print(torch.sum(output_prob[0]).item())"],"id":"5_RGdqCam_zk"},{"cell_type":"code","execution_count":null,"metadata":{"id":"SeuCWL5zm_zk"},"outputs":[],"source":["# The indices corresponding to the maximum values are obtained\n","_, pred_labels = torch.max(output, dim=1)"],"id":"SeuCWL5zm_zk"},{"cell_type":"code","execution_count":null,"metadata":{"id":"gwFXriFPm_zl"},"outputs":[],"source":["# Viewing prediction results in a batch\n","fig = plt.figure(figsize=(30, 8))\n","bs = 32 if len(labels) > 32 else len(labels)\n","for k in range(bs):\n","    ax = fig.add_subplot(int(np.ceil(bs / 8)), 8, k + 1, xticks=[], yticks=[])\n","    ax.imshow(images[k].numpy().squeeze(), cmap='gray')\n","    # The predicted label, the probability and the correct label are included\n","    ax.set_title('Pred: {} with p={:.4f} - True: {}'.format(\n","        pred_labels[k].item(), output_prob[k, pred_labels[k].item()].item(),\n","        str(labels[k].item())))"],"id":"gwFXriFPm_zl"},{"cell_type":"markdown","metadata":{"id":"gsppIhJnm_zl"},"source":["### Mapping with class_to_idx\n","\n","This time we have used one of the datasets that come by default in pytorch and that has simplified things. On other occasions, the normal thing will be that you use your own datasets or obtained from other sources, but that are not the ones that are downloaded by default in pytorch. In these cases, you may have a data folder that in turn has several subfolders. In each of these subfolders would be the images. For example, let's imagine that we have on our computer all the handwritten digit images from MNIST that we want to train with. They are in a folder that in turn contains 10 folders with the names folder01, folder02, folder03, ...\n","\n","In this case we would not have downloaded anything from pytorch. We would have simply referenced our project folder on dataset load:\n","```\n","train_data = datasets.ImageFolder(TRAIN_FOLDER_PATH, transform=transform)\n","```\n","\n","Well, in this way the values of the _classes_ and _class_to_idx_ attributes of the _dataset_ would be the following:\n","```\n","print(train_data.classes)\n",">>> ['folder01', 'folder02', 'folder03', 'folder04', 'folder05', 'folder06', 'folder07', 'folder08', 'folder09', 'folder10']\n","\n","print(train_data.class_to_idx)\n",">>> {'folder01': 0,\n","     'folder02': 1,\n","     'folder03': 2,\n","     'folder04': 3,\n","     'folder05': 4,\n","     'folder06': 5,\n","     'folder07': 6,\n","     'folder08': 7,\n","     'folder09': 8,\n","     'folder10': 9}\n","```\n","You may have noticed by now that this does not identify what is in each folder. The index is just a folder pointer, but it doesn't give any information about the content.\n","\n","So you can't know what's in each folder, unless you go in and look at it, and rename the folders. In practice this is not always possible, since if you work with images of poisonous mushrooms you may not be able to identify them from the image. For this reason, datasets often come with a file that identifies the content. For example, let's imagine that in this case it came with a .json file that when loaded we had a dictionary-type variable with the following values.\n","```\n","import json\n","\n","# Load the json file\n","with open('archive.json', 'r') as f:\n","    foldername_to_category = json.load(f)\n","\n","print(foldername_to_category)\n",">>> {'folder01': 'images of one',\n","     'folder02': 'images of two',\n","     'folder03': 'images of three',\n","     'folder04': 'images of four',\n","     'folder05': 'images of five',\n","     'folder06': 'images of six',\n","     'folder07': 'images of seven',\n","     'folder08': 'images of eight',\n","     'folder09': 'images of nine',\n","     'folder10': 'images of zero'}\n","```\n","\n","So we would no longer have any problem to identify everything. The training would have been the same as the one carried out. Simply, when the system prediction was a given index, we would know which images it refers to by doing:\n","\n","```\n","print(prediction)\n",">>> 0\n","print(train_data.classes[prediction])\n",">>> 'folder01'\n","print(foldername_to_category[train_data.classes[prediction]])\n",">>> 'images of one'\n","```\n","\n","Possibly the best solution would be to create a dictionary that would relate the indices to the actual contents.\n"],"id":"gsppIhJnm_zl"},{"cell_type":"code","execution_count":null,"metadata":{"id":"U2uETaIUm_zm"},"outputs":[],"source":["# Example\n","# Imagine that the network had trained with images of mushrooms and not with digits\n","# You have train_data.class_to_idx and train_data.classes\n","print('class_to_idx:\\n{}\\n'.format(train_data.class_to_idx))\n","print('classes:\\n{}\\n'.format(train_data.classes))\n","\n","# On the other hand, you are provided with the variable fname_to_cat below,\n","# which has the structure {key: folder name, value: name of a mushroom} (it is\n","# understood, logically, that if this assumption were fulfilled we would have\n","# images of that type in that folder of specific mushroom and of no other type).\n","# From this data, it generates a dictionary-like object called index_to_cat\n","# with the structure {key: output index, value: mushroom name}\n","fname_to_cat =  {'0 - zero': 'amanita caesarea',\n","                 '1 - one': 'agaricus campester',\n","                 '2 - two': 'boletus edulis',\n","                 '3 - three': 'lactarius deliciosus',\n","                 '4 - four': 'cantharellus cibarius',\n","                 '5 - five': 'tuber melanosporum',\n","                 '6 - six': 'pleurotus eryngii',\n","                 '7 - seven': 'calocybe gambosa',\n","                 '8 - eight': 'cantharellus lutescens',\n","                 '9 - nine': 'craterellus cornucopioides'}\n","\n","# One option would be the following\n","index_to_cat = {idx: fname_to_cat[train_data.classes[idx]] for idx, foldername\n","                in enumerate(train_data.classes)}\n","\n","print('index_to_cat:\\n{}\\n'.format(index_to_cat))"],"id":"U2uETaIUm_zm"},{"cell_type":"code","execution_count":null,"metadata":{"id":"h3BantCXm_zn"},"outputs":[],"source":[],"id":"h3BantCXm_zn"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[]},"accelerator":"GPU","gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}