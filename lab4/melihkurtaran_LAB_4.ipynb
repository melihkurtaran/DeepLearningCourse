{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1x-QAgitB-S5rxGGDqxsJ299ZQTfYtOhb\" width=180, align=\"center\"/>\n",
        "\n",
        "Master's degree in Intelligent Systems\n",
        "\n",
        "Subject: 11754 - Deep Learning\n",
        "\n",
        "Year: 2022-2023\n",
        "\n",
        "Professor: Miguel √Ångel Calafat Torrens\n"
      ],
      "metadata": {
        "id": "yxXs41mhQelR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LAB 4\n",
        "\n",
        "In this lab you have to deliver two files.\n",
        "\n",
        "* On the one hand you must deliver the file helper_PR4.py adding the functions described in problem 1.\n",
        "\n",
        "* On the other hand, you must deliver the notebook `LSS4.2.ipynb` suitably modified according to the instructions of problem 2. In it you can modify as many cells as you consider appropriate to carry out the proposed objective.\n",
        "\n",
        "You don't have to deliver this notebook (`LAB-4.ipynb`)."
      ],
      "metadata": {
        "id": "y4Syr2VEMNr5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1\n",
        "\n",
        "In the `LSS4.1.ipynb` notebook you have trained and validated a model. The validation is to realize if overfitting is taking place; however, the true test for the model are the results with the test dataset.\n",
        "\n",
        "In this exercise you will create two functions and leave them saved in the script called `helper_PR4.py`.\n",
        "\n",
        "The first function will be the `test_pass()` function. This function is, for the test data set, the equivalent of `train_pass()` for the training data set, or the equivalent of `valid_pass()` for the validation data set. Both functions have been defined in the `LSS4.1` notebook.\n",
        "\n",
        "Following is the signature of the function, the description of the operation and the names of the output parameters."
      ],
      "metadata": {
        "id": "jabEbC-jMN7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "dXEvSSh5lTWQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# As with train_pass and valid_pass, we define a function for a single test\n",
        "# step. This function returns the losses and also the output of the model.\n",
        "\n",
        "# Remember that the output of the model will have dimensions of b x 10\n",
        "def test_pass(data, target, model, criterion):\n",
        "    \"\"\"\n",
        "    Evaluates a given model on a single batch of data.\n",
        "\n",
        "    Args:\n",
        "        data (torch.Tensor): Input data tensor.\n",
        "        target (torch.Tensor): Target tensor.\n",
        "        model (torch.nn.Module): PyTorch model to be evaluated.\n",
        "        criterion (torch.nn.Module): Loss function.\n",
        "\n",
        "    Returns:\n",
        "        Tuple containing the loss value and output tensor.\n",
        "    \"\"\"\n",
        "    # set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # move data and target to device\n",
        "    data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "\n",
        "    # perform forward pass\n",
        "    with torch.no_grad():\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "    # return loss value and output tensor\n",
        "    return loss.item(), output\n"
      ],
      "metadata": {
        "id": "cVqm29laLj6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the previous function is finished and saved in `helper_PR4.py` you must prepare another function. In this case it is the `do_test()` function. This is a function in which one pass will be made through the entire test dataset and the accuracy, unit losses and model output will be computed."
      ],
      "metadata": {
        "id": "Q1farcFURlAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def do_test(model, loaders, criterion):\n",
        "    \"\"\"\n",
        "    Test the performance of the given model on the test set.\n",
        "    \n",
        "    Args:\n",
        "        model: A PyTorch model.\n",
        "        loaders: A dictionary with 'test' DataLoader.\n",
        "        criterion: A PyTorch loss function.\n",
        "\n",
        "    Returns:\n",
        "        accuracy: A float representing the accuracy on the test set.\n",
        "        test_loss: A float representing the average test loss.\n",
        "        all_outputs: A tensor containing the model outputs on the test set\n",
        "    \"\"\"\n",
        "\n",
        "    # Set the model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # move model to device\n",
        "    model.to(DEVICE)\n",
        "\n",
        "    # create DataLoader for test set\n",
        "    test_loader = loaders['test']\n",
        "\n",
        "    # initialize variables\n",
        "    test_loss = 0.0\n",
        "    num_correct = 0\n",
        "    all_outputs = torch.tensor([]).to(DEVICE)\n",
        "\n",
        "    # evaluate model on test set\n",
        "    for data, target in test_loader:\n",
        "\n",
        "        # perform test pass\n",
        "        loss, output = test_pass(data, target, model, criterion)\n",
        "\n",
        "        # update loss and accuracy\n",
        "        test_loss += loss.item() * data.size(0)\n",
        "        num_correct += torch.sum(torch.argmax(output, dim=1) == target).item()\n",
        "\n",
        "        # concatenate all outputs\n",
        "        all_outputs = torch.cat((all_outputs, output), dim=0)\n",
        "\n",
        "    # calculate average test loss and accuracy\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    accuracy = num_correct / len(test_loader.dataset)\n",
        "\n",
        "    # return accuracy, test loss and all outputs\n",
        "    return accuracy, test_loss, all_outputs"
      ],
      "metadata": {
        "id": "-Q7_O69BTLoD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 2\n",
        "\n",
        "The second problem is to completely re-run the `LSS4.2` notebook by introducing the following change: you have to define your own CustomDataset class from the PyTorch Dataset class.\n",
        "\n",
        "For this you can use the following model. The class must have at least the properties and methods defined below.\n",
        "\n",
        "The input `im_paths` should be a list with the path of every image in the dataset. In the `__init__` function you should extract all the labels of the images. The label of an image is a string with the letters of the filename untill the first digit is found. For example, `shine123.jpg` and `shine21.jpg` will have the label `shine`; `rain215.jpg` will have the label `rain`, and so on.\n",
        "\n",
        "The labels should be recorded as integers for the training, so in `self.labels` you should store a list of labels in integer format (you can choose which number equals which class; a usual option is sorted in alphabetical order)"
      ],
      "metadata": {
        "id": "oHO-CDyS3pRY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from typing import List\n",
        "from PIL import Image\n",
        "import torch\n",
        "\n",
        "# Define new class Dataset specific for this project\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, im_paths, transform=None):\n",
        "        self.image_paths = im_paths  # List of paths as strings\n",
        "        self.transform = transform  # Transformations\n",
        "        self.classes = sorted(set([self.get_label(path) for path in im_paths]))  # Unique labels as strings\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}  # Dictionary mapping classes to indexes. For\n",
        "                                  # example: {'cloudy':0, `rain`:1, ...}\n",
        "        self.labels = [self.class_to_idx[self.get_label(path)] for path in im_paths]\n",
        "        # List of integers with labels corresponding to the\n",
        "                            # list of paths (image_paths)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        # Don't do anything in this function. It is provided for you\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Do all the necessary treatment of data. Remember that when you apply\n",
        "        # next() to the daloader, it will call this function. So you have to\n",
        "        # do all the necessary steps to deliver the image and the label.\n",
        "\n",
        "        # You don't have to worry about the batch; it's controlled by the\n",
        "        # dataloader. You just have to return an image and label pointed by\n",
        "        # an index (idx)\n",
        "        \n",
        "        path = self.image_paths[idx]\n",
        "        image = Image.open(path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, torch.tensor(label)\n",
        "\n",
        "    def get_label(self, path):\n",
        "        \"\"\"\n",
        "        Returns the label of an image, which is the string of characters\n",
        "        in the filename until the first digit is found.\n",
        "        \"\"\"\n",
        "        filename = path.split('/')[-1]  # get the filename from the path\n",
        "        label = ''\n",
        "        for char in filename:\n",
        "            if char.isdigit():\n",
        "                break\n",
        "            label += char\n",
        "        return label"
      ],
      "metadata": {
        "id": "EOgll5QJ4eYJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}